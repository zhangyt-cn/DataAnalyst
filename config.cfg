[llm]
model = meta-llama/Llama-3.3-70B-Instruct
temperature = 0.7
top_p = 0.9
n = 1
max_tokens = 1024
seed = 42
